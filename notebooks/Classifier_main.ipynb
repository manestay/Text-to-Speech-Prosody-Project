{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "import re\n",
    "from spherecluster import SphericalKMeans\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "\n",
    "def generate_data(file_name, features, continuous_feats):\n",
    "    break_label = 'word_tobi_break_index'\n",
    "    break_set = set([\"4\", \"4-\", \"4p\"])\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.DictReader(f) # DictReader fixes off-by-one error from before\n",
    "        for i, l in enumerate(reader):\n",
    "            feats = {}\n",
    "            for feat in features:\n",
    "                if feat in continuous_feats:\n",
    "                    feats[feat] = int(l[feat])\n",
    "                else:\n",
    "                    feats[feat] = l[feat]\n",
    "#             feats = {feat: l[feat] for feat in features}\n",
    "#             # convert some to continuous features\n",
    "#             for feat in continuous_feats:\n",
    "#                 feats[feat] = float(feats[feat])\n",
    "            x_data.append(feats)\n",
    "            label = l[break_label] in break_set\n",
    "            y_data.append(label)\n",
    "    return x_data, y_data\n",
    "\n",
    "def classify_my_model(pipeline, param_grid, X, y, model_name, scorer='f1', excluded_features=set()):\n",
    "    print('#'*35, model_name, '#'*35)\n",
    "    folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=int(time()))\n",
    "#     param_grid['selector__percentile'] = [10, 25, 50, 90, 95, 100]\n",
    "    \n",
    "    for entry in X:\n",
    "        for f in excluded_features:\n",
    "            if f in entry:\n",
    "                entry.pop(f)\n",
    "    \n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      param_grid,\n",
    "                      scoring=scorer,\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "    t0 = time()\n",
    "    gs.fit(X, y)\n",
    "    train_time = time() - t0\n",
    "    print(\"Train time: %0.3fs\" % train_time)\n",
    "#     print(\"Real train time: %0.3fs\" % (train_time * (TOTAL_COUNT/DEV_COUNT)))\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    best_params = gs.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))\n",
    "    return gs.best_score_, gs.best_estimator_\n",
    "    \n",
    "#     with open(model_name+'_best_'+type(clf).__name__+\".pkl\", 'wb') as handle:\n",
    "#         pickle.dump(best_model, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classifier models\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fdot25_scorer = make_scorer(fbeta_score, beta=.25)\n",
    "dict_vectorizer = DictVectorizer()\n",
    "# select_percentile = SelectPercentile(percentile=100)\n",
    "\n",
    "clf_map = [\n",
    "#     (\n",
    "#         BernoulliNB(),\n",
    "#         {\n",
    "#             'clf__alpha': [.001, .01, .1, 1],\n",
    "#             'clf__fit_prior': [True, False],\n",
    "#         }\n",
    "#     ),\n",
    "    (\n",
    "        LinearSVC(),\n",
    "        {\n",
    "            'clf__C': [.1, 1, 10, 100],\n",
    "            'clf__penalty': ['l2'],\n",
    "            'clf__loss': ['hinge', 'squared_hinge'],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        LogisticRegression(),\n",
    "        {\n",
    "            'clf__penalty': ['l1','l2'],\n",
    "            'clf__fit_intercept': [True, False],\n",
    "            'clf__C':[.1, 1, 10, 100],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        RandomForestClassifier(random_state=2557),\n",
    "        {\n",
    "            'clf__n_estimators': [10, 20],\n",
    "            'clf__max_features': [\"auto\", \"log2\",None]\n",
    "        }\n",
    "    ),\n",
    "#     (\n",
    "#         DecisionTreeClassifier(random_state=2557),\n",
    "#         {\n",
    "#             'clf__criterion': [\"gini\", \"entropy\"]\n",
    "#         }\n",
    "#     ),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"../info-status/games-data-20180413.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'word',\n",
    "#     'word_pos_tag',\n",
    "#     'word_pos_tag_simplified',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables',]\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.83      1.00      0.90     11618\n",
      "       True       0.00      0.00      0.00      2448\n",
      "\n",
      "avg / total       0.68      0.83      0.75     14066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# majority class baseline classifier\n",
    "y_pred = [0] * len(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 11.402s\n",
      "Best score: 0.540\n",
      "\tclf__alpha: 1\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.91      0.90     11618\n",
      "       True       0.54      0.51      0.52      2448\n",
      "\n",
      "avg / total       0.84      0.84      0.84     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   59.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 61.202s\n",
      "Best score: 0.668\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'squared_hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.70      0.38      0.49      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.85     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 135.619s\n",
      "Best score: 0.678\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.73      0.34      0.46      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.84     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   11.8s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 21.193s\n",
      "Best score: 0.518\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.91      0.90     11618\n",
      "       True       0.53      0.45      0.49      2448\n",
      "\n",
      "avg / total       0.83      0.83      0.83     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with syntactic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 11.434s\n",
      "Best score: 0.512\n",
      "\tclf__alpha: 1\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.88      0.90     11618\n",
      "       True       0.52      0.60      0.56      2448\n",
      "\n",
      "avg / total       0.84      0.83      0.84     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   54.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 56.338s\n",
      "Best score: 0.674\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'squared_hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.96      0.92     11618\n",
      "       True       0.71      0.42      0.53      2448\n",
      "\n",
      "avg / total       0.86      0.87      0.86     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 122.417s\n",
      "Best score: 0.687\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.72      0.39      0.50      2448\n",
      "\n",
      "avg / total       0.85      0.87      0.85     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    8.6s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 18.527s\n",
      "Best score: 0.527\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.91      0.90     11618\n",
      "       True       0.53      0.47      0.50      2448\n",
      "\n",
      "avg / total       0.83      0.84      0.83     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "#     'word_pos_tag',\n",
    "#     'word_pos_tag_simplified',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables',]\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "    \n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with syntactic features and current and previous mention information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 23.152s\n",
      "Best score: 0.495\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.88      0.89     11618\n",
      "       True       0.50      0.59      0.54      2448\n",
      "\n",
      "avg / total       0.84      0.83      0.83     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 82.325s\n",
      "Best score: 0.684\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.97      0.92     11618\n",
      "       True       0.73      0.33      0.46      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.84     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 179.075s\n",
      "Best score: 0.690\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.72      0.39      0.51      2448\n",
      "\n",
      "avg / total       0.85      0.87      0.85     14066\n",
      "\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 229.150s\n",
      "Best score: 0.678\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.98      0.92     11618\n",
      "       True       0.74      0.31      0.44      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.84     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   16.6s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 31.051s\n",
      "Best score: 0.531\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.92      0.90     11618\n",
      "       True       0.54      0.47      0.50      2448\n",
      "\n",
      "avg / total       0.83      0.84      0.83     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables',]\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "    \n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_mentioned(X_data):\n",
    "    for i in range(len(X_data)):\n",
    "        X_data[i]['mentioned'] = True if X_data[i]['Most_Recent_Mention'] else False\n",
    "\n",
    "def set_input_num_mentions(X_data):\n",
    "    for i in range(len(X_data)):\n",
    "        num = X_data[i]['Number_Of_Coref_Mentions']\n",
    "        X_data[i]['Number_Of_Coref_Mentions'] = int(num) if num else 0\n",
    "\n",
    "def get_input_far_back_mentioned(X_data):\n",
    "    for i in range(len(X_data)):\n",
    "        curr_time = float(X_data[i]['word_end_time'])\n",
    "        most_recent_time = X_data[i]['Most_Recent_Mention']\n",
    "        most_recent_time = float(most_recent_time) if most_recent_time else curr_time # if no Most_Recent_Mention data, value = 0\n",
    "        X_data[i]['time_between_mentions'] = curr_time - most_recent_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_between_mentions': 0.0, 'Recent_Explicit_Mention_PoS': '', 'Recent_Explicit_Mention_Syntactic_Function': '', 'word_number_in_task': '1', 'word': 'yup', 'total_number_of_words_in_turn': '1', 'Most_Recent_Mention_PoS': '', 'Recent_Implicit_Mention_Syntactic_Function': '', 'word_number_in_turn': '1', 'total_number_of_words_in_task': '50', 'Recent_Implicit_Mention_PoS': '', 'Number_Of_Coref_Mentions': 0, 'Stanford_PoS': 'NN', 'word_number_of_syllables': 1.0, 'mentioned': False, 'syntactic_function': 'ROOT', 'Most_Recent_Mention_Syntactic_Function': ''}\n",
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 24.116s\n",
      "Best score: 0.488\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.88      0.89     11618\n",
      "       True       0.49      0.56      0.52      2448\n",
      "\n",
      "avg / total       0.83      0.82      0.83     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 147.904s\n",
      "Best score: 0.665\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.97      0.92     11618\n",
      "       True       0.73      0.33      0.46      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.84     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 160.188s\n",
      "Best score: 0.687\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.72      0.39      0.51      2448\n",
      "\n",
      "avg / total       0.85      0.87      0.85     14066\n",
      "\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 228.650s\n",
      "Best score: 0.682\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.74      0.36      0.49      2448\n",
      "\n",
      "avg / total       0.85      0.87      0.85     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   14.5s remaining:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 27.965s\n",
      "Best score: 0.539\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.92      0.90     11618\n",
      "       True       0.54      0.47      0.51      2448\n",
      "\n",
      "avg / total       0.83      0.84      0.83     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "    'Most_Recent_Mention',\n",
    "    'Number_Of_Coref_Mentions',\n",
    "    'word_end_time'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "get_input_mentioned(x_data)\n",
    "set_input_num_mentions(x_data)\n",
    "get_input_far_back_mentioned(x_data)\n",
    "\n",
    "excluded_features = ['Most_Recent_Mention','word_end_time']\n",
    "for entry in x_data:\n",
    "    for feature in excluded_features:\n",
    "        if feature in entry:\n",
    "            entry.pop(feature)\n",
    "print(x_data[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "    \n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding POS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dist_end_turn(x_data):\n",
    "    # distance from end of turn\n",
    "    DIST_END_TURN = \"DIST_END_TURN\"\n",
    "    for i in range(len(x_data)):\n",
    "        x_data[i][DIST_END_TURN] = int(x_data[i]['total_number_of_words_in_turn']) - int(x_data[i]['word_number_in_turn'])\n",
    "        \n",
    "def add_pos_bigram(x_data, left=True, right=True):\n",
    "    POS_TURN_BIGRAM_LEFT = \"POS_TURN_BIGRAM_LEFT\"\n",
    "    POS_TURN_BIGRAM_RIGHT = \"POS_TURN_BIGRAM_RIGHT\"\n",
    "    \n",
    "    def add_left_bigram(x_data):\n",
    "        if x_data[i]['word_number_in_turn'] == '1':\n",
    "            x_data[i][POS_TURN_BIGRAM_LEFT] = 'BEGIN/'+x_data[i]['Stanford_PoS']\n",
    "        else:\n",
    "            x_data[i][POS_TURN_BIGRAM_LEFT] = x_data[i-1]['Stanford_PoS']+\"/\"+x_data[i]['Stanford_PoS']\n",
    "    def add_right_bigram(x_data):\n",
    "        word_number, total_word_number = int(x_data[i]['word_number_in_turn']), int(x_data[i]['total_number_of_words_in_turn'])\n",
    "        if word_number == total_word_number:\n",
    "            x_data[i][POS_TURN_BIGRAM_RIGHT] = x_data[i]['Stanford_PoS']+\"/END\"\n",
    "        else:\n",
    "            x_data[i][POS_TURN_BIGRAM_RIGHT] = x_data[i]['Stanford_PoS']+\"/\"+x_data[i+1]['Stanford_PoS']\n",
    "            \n",
    "    if not left: add_left_bigram = lambda x: None\n",
    "    if not right: add_right_bigram = lambda x: None\n",
    "        \n",
    "    for i in range(len(x_data)):\n",
    "        add_left_bigram(x_data)\n",
    "        add_right_bigram(x_data)\n",
    "\n",
    "def add_word_bigram(x_data, left=True, right=True):\n",
    "    POS_TURN_BIGRAM_LEFT = \"POS_WORD_BIGRAM_LEFT\"\n",
    "    POS_TURN_BIGRAM_RIGHT = \"POS_WORD_BIGRAM_RIGHT\"\n",
    "    \n",
    "    def add_left_bigram(x_data):\n",
    "        if x_data[i]['word_number_in_turn'] == '1':\n",
    "            x_data[i][POS_TURN_BIGRAM_LEFT] = 'BEGIN/'+x_data[i]['word']\n",
    "        else:\n",
    "            x_data[i][POS_TURN_BIGRAM_LEFT] = x_data[i-1]['word']+\"/\"+x_data[i]['word']\n",
    "    def add_right_bigram(x_data):\n",
    "        word_number, total_word_number = int(x_data[i]['word_number_in_turn']), int(x_data[i]['total_number_of_words_in_turn'])\n",
    "        if word_number == total_word_number:\n",
    "            x_data[i][POS_TURN_BIGRAM_RIGHT] = x_data[i]['word']+\"/END\"\n",
    "        else:\n",
    "            x_data[i][POS_TURN_BIGRAM_RIGHT] = x_data[i]['word']+\"/\"+x_data[i+1]['word']\n",
    "            \n",
    "    if not left: add_left_bigram = lambda x: None\n",
    "    if not right: add_right_bigram = lambda x: None\n",
    "        \n",
    "    for i in range(len(x_data)):\n",
    "        add_left_bigram(x_data)\n",
    "        add_right_bigram(x_data)\n",
    "        \n",
    "def add_pos_trigram(x_data):\n",
    "    POS_TURN_TRIGRAM = \"POS_TURN_TRIGRAM\"\n",
    "    for i in range(len(x_data)):\n",
    "        # to the left\n",
    "        left = \"BEGIN\"\n",
    "        if x_data[i]['word_number_in_turn'] != '1':\n",
    "            left = x_data[i-1]['Stanford_PoS']\n",
    "        # to the right\n",
    "        right = \"END\"\n",
    "        word_number, total_word_number = int(x_data[i]['word_number_in_turn']), int(x_data[i]['total_number_of_words_in_turn'])\n",
    "        if x_data[i]['word_number_in_turn'] != x_data[i]['total_number_of_words_in_turn']:\n",
    "            right = x_data[i+1]['Stanford_PoS']\n",
    "        x_data[i][POS_TURN_TRIGRAM] = left+\"/\"+x_data[i]['Stanford_PoS']+\"/\"+right\n",
    "        \n",
    "def add_is_stutter(x_data):\n",
    "    IS_STUTTER = \"IS_STUTTER\"\n",
    "    for i in range(len(x_data)):\n",
    "        x_data[i][IS_STUTTER] = x_data[i]['word'][-1] == '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With bigram features, without coref mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   42.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 46.236s\n",
      "Best score: 0.521\n",
      "\tclf__alpha: 1\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.86      0.90     11618\n",
      "       True       0.52      0.69      0.59      2448\n",
      "\n",
      "avg / total       0.86      0.83      0.84     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 230.678s\n",
      "Best score: 0.725\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.96      0.93     11618\n",
      "       True       0.75      0.50      0.60      2448\n",
      "\n",
      "avg / total       0.88      0.88      0.88     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 234.669s\n",
      "Best score: 0.737\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.77      0.50      0.61      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 414.595s\n",
      "Best score: 0.730\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.98      0.93     11618\n",
      "       True       0.78      0.38      0.51      2448\n",
      "\n",
      "avg / total       0.86      0.87      0.85     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   23.4s remaining:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 45.519s\n",
      "Best score: 0.593\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.92      0.91     11618\n",
      "       True       0.59      0.53      0.56      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.85     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "#     'Most_Recent_Mention',\n",
    "#     'Number_Of_Coref_Mentions',\n",
    "#     'word_end_time'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "add_dist_end_turn(x_data)\n",
    "add_pos_bigram(x_data)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "    \n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With bigram features, with coref mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recent_Explicit_Mention_PoS': '', 'word_number_in_task': '1', 'word': 'yup', 'total_number_of_words_in_turn': '1', 'total_number_of_words_in_task': '50', 'Stanford_PoS': 'NN', 'syntactic_function': 'ROOT', 'POS_TURN_BIGRAM_RIGHT': 'NN/END', 'Recent_Explicit_Mention_Syntactic_Function': '', 'time_between_mentions': 0.0, 'Recent_Implicit_Mention_PoS': '', 'POS_TURN_BIGRAM_LEFT': 'BEGIN/NN', 'Most_Recent_Mention_PoS': '', 'Recent_Implicit_Mention_Syntactic_Function': '', 'Most_Recent_Mention_Syntactic_Function': '', 'word_number_in_turn': '1', 'Number_Of_Coref_Mentions': 0, 'DIST_END_TURN': 0, 'mentioned': False, 'word_number_of_syllables': 1.0}\n",
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   33.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 37.017s\n",
      "Best score: 0.519\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.87      0.90     11618\n",
      "       True       0.52      0.68      0.59      2448\n",
      "\n",
      "avg / total       0.86      0.83      0.84     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 220.400s\n",
      "Best score: 0.720\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.75      0.49      0.59      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.87     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 245.104s\n",
      "Best score: 0.739\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: False\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.77      0.50      0.61      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 401.336s\n",
      "Best score: 0.733\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.98      0.93     11618\n",
      "       True       0.79      0.38      0.51      2448\n",
      "\n",
      "avg / total       0.87      0.87      0.86     14066\n",
      "\n",
      "################################### DecisionTreeClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   24.8s remaining:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   32.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 46.967s\n",
      "Best score: 0.598\n",
      "\tclf__criterion: 'gini'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.92      0.91     11618\n",
      "       True       0.60      0.53      0.56      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.85     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no is_stutter\n",
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "    'Most_Recent_Mention',\n",
    "    'Number_Of_Coref_Mentions',\n",
    "    'word_end_time'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "add_dist_end_turn(x_data)\n",
    "add_pos_bigram(x_data)\n",
    "get_input_mentioned(x_data)\n",
    "set_input_num_mentions(x_data)\n",
    "get_input_far_back_mentioned(x_data)\n",
    "\n",
    "excluded_features = ['Most_Recent_Mention','word_end_time']\n",
    "for entry in x_data:\n",
    "    for feature in excluded_features:\n",
    "        if feature in entry:\n",
    "            entry.pop(feature)\n",
    "print(x_data[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "    \n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recent_Explicit_Mention_PoS': '', 'word_number_in_task': '1', 'word': 'yup', 'total_number_of_words_in_turn': '1', 'total_number_of_words_in_task': '50', 'Stanford_PoS': 'NN', 'syntactic_function': 'ROOT', 'POS_TURN_BIGRAM_RIGHT': 'NN/END', 'Recent_Explicit_Mention_Syntactic_Function': '', 'time_between_mentions': 0.0, 'Recent_Implicit_Mention_PoS': '', 'POS_TURN_BIGRAM_LEFT': 'BEGIN/NN', 'Most_Recent_Mention_PoS': '', 'Recent_Implicit_Mention_Syntactic_Function': '', 'Most_Recent_Mention_Syntactic_Function': '', 'IS_STUTTER': False, 'Number_Of_Coref_Mentions': 0, 'DIST_END_TURN': 0, 'word_number_of_syllables': 1.0, 'mentioned': False, 'word_number_in_turn': '1'}\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "    'Most_Recent_Mention',\n",
    "    'Number_Of_Coref_Mentions',\n",
    "    'word_end_time'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "add_dist_end_turn(x_data)\n",
    "add_pos_bigram(x_data)\n",
    "add_is_stutter(x_data)\n",
    "\n",
    "get_input_mentioned(x_data)\n",
    "set_input_num_mentions(x_data)\n",
    "get_input_far_back_mentioned(x_data)\n",
    "\n",
    "excluded_features = ['Most_Recent_Mention','word_end_time']\n",
    "for entry in x_data:\n",
    "    for feature in excluded_features:\n",
    "        if feature in entry:\n",
    "            entry.pop(feature)\n",
    "print(x_data[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 30.654s\n",
      "Best score: 0.520\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.87      0.90     11618\n",
      "       True       0.52      0.68      0.59      2448\n",
      "\n",
      "avg / total       0.86      0.83      0.84     14066\n",
      "\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 212.602s\n",
      "Best score: 0.720\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.96      0.93     11618\n",
      "       True       0.73      0.51      0.60      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.87     14066\n",
      "\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 228.341s\n",
      "Best score: 0.738\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.77      0.51      0.61      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 341.995s\n",
      "Best score: 0.736\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.98      0.93     11618\n",
      "       True       0.79      0.39      0.53      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.86     14066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 29.672s\n",
      "Best score: 0.528\n",
      "\tclf__alpha: 1\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.86      0.90     11618\n",
      "       True       0.52      0.71      0.60      2448\n",
      "\n",
      "avg / total       0.86      0.84      0.85     14066\n",
      "\n",
      "0.8361296743921512\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 155.162s\n",
      "Best score: 0.726\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.96      0.93     11618\n",
      "       True       0.75      0.52      0.62      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "0.8863216266173752\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 188.210s\n",
      "Best score: 0.735\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.77      0.51      0.61      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "0.887814588369117\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 390.040s\n",
      "Best score: 0.728\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.97      0.93     11618\n",
      "       True       0.77      0.41      0.53      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.86     14066\n",
      "\n",
      "0.8757287075216835\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "add_dist_end_turn(x_data)\n",
    "add_pos_bigram(x_data)\n",
    "add_pos_trigram(x_data)\n",
    "add_is_stutter(x_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POS_TURN_TRIGRAM': 'BEGIN/NN/END', 'Recent_Explicit_Mention_PoS': '', 'word_number_in_task': '1', 'word': 'yup', 'total_number_of_words_in_turn': '1', 'total_number_of_words_in_task': '50', 'Stanford_PoS': 'NN', 'syntactic_function': 'ROOT', 'IS_STUTTER': False, 'POS_TURN_BIGRAM_RIGHT': 'NN/END', 'Recent_Explicit_Mention_Syntactic_Function': '', 'time_between_mentions': 0.0, 'Recent_Implicit_Mention_PoS': '', 'POS_TURN_BIGRAM_LEFT': 'BEGIN/NN', 'Most_Recent_Mention_PoS': '', 'Recent_Implicit_Mention_Syntactic_Function': '', 'Most_Recent_Mention_Syntactic_Function': '', 'word_number_in_turn': '1', 'Number_Of_Coref_Mentions': 0, 'DIST_END_TURN': 0, 'mentioned': False, 'word_number_of_syllables': 1.0}\n",
      "################################### BernoulliNB ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 33.305s\n",
      "Best score: 0.524\n",
      "\tclf__alpha: 1\n",
      "\tclf__fit_prior: True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.86      0.90     11618\n",
      "       True       0.52      0.69      0.59      2448\n",
      "\n",
      "avg / total       0.86      0.83      0.84     14066\n",
      "\n",
      "0.8349210863074079\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 175.566s\n",
      "Best score: 0.711\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.96      0.93     11618\n",
      "       True       0.74      0.50      0.60      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.87     14066\n",
      "\n",
      "0.8827669557798948\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 203.261s\n",
      "Best score: 0.737\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.97      0.93     11618\n",
      "       True       0.76      0.51      0.61      2448\n",
      "\n",
      "avg / total       0.88      0.89      0.88     14066\n",
      "\n",
      "0.8876013081188682\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 397.991s\n",
      "Best score: 0.730\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.97      0.93     11618\n",
      "       True       0.76      0.46      0.57      2448\n",
      "\n",
      "avg / total       0.87      0.88      0.87     14066\n",
      "\n",
      "0.8802786861936585\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "    'syntactic_function',\n",
    "    'Most_Recent_Mention_Syntactic_Function',\n",
    "    'Recent_Explicit_Mention_Syntactic_Function',\n",
    "    'Recent_Implicit_Mention_Syntactic_Function',\n",
    "    'Most_Recent_Mention_PoS',\n",
    "    'Recent_Explicit_Mention_PoS',\n",
    "    'Recent_Implicit_Mention_PoS',\n",
    "    'Most_Recent_Mention',\n",
    "    'Number_Of_Coref_Mentions',\n",
    "    'word_end_time'\n",
    "]\n",
    "\n",
    "continuous_feats = ['word_number_of_syllables']\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "add_dist_end_turn(x_data)\n",
    "add_pos_bigram(x_data)\n",
    "add_pos_trigram(x_data)\n",
    "add_is_stutter(x_data)\n",
    "\n",
    "get_input_mentioned(x_data)\n",
    "set_input_num_mentions(x_data)\n",
    "get_input_far_back_mentioned(x_data)\n",
    "\n",
    "excluded_features = ['Most_Recent_Mention','word_end_time']\n",
    "for entry in x_data:\n",
    "    for feature in excluded_features:\n",
    "        if feature in entry:\n",
    "            entry.pop(feature)\n",
    "print(x_data[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "\n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding word embedding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G Word embeddings: 1193514\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_FILE = \"/mnt/e/word2vec/glove.twitter.27B.200d.txt\"\n",
    "# EMBEDDING_DIM = 50\n",
    "#load embeddings\n",
    "gembeddings_index = {}\n",
    "with open(EMBEDDINGS_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "\n",
    "print('G Word embeddings:', len(gembeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(x_data, embeddings_d):\n",
    "    dim_len = len(embeddings_d['the'])\n",
    "    for i in range(len(x_data)):\n",
    "        vector = [0] * dim_len\n",
    "        word = x_data[i]['word']\n",
    "        if word in embeddings_d:\n",
    "            vector = embeddings_d[word]\n",
    "        \n",
    "        for dim in range(dim_len):\n",
    "            x_data[i]['embedding_dim{}'.format(dim)] = vector[dim]\n",
    "\n",
    "\n",
    "def add_embedding_cluster(x_data, embeddings_d, sphere=True, clusters=10):\n",
    "    dim_len = len(embeddings_d['the'])\n",
    "    x_words = [x['word'].lower() for x in x_data]\n",
    "    embeddings = [embeddings_d.get(word) if word in embeddings_d else [0.0] * dim_len for word in x_words]\n",
    "    \n",
    "    if sphere: # equivalent to cosine similarity\n",
    "        print('doing spherical kmeans')\n",
    "        kmeans = SphericalKMeans(n_clusters=clusters, random_state=2557).fit(embeddings)\n",
    "    else: # Euclidean distance\n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=2557).fit(embeddings)\n",
    "\n",
    "    for i in range(len(x_data)):\n",
    "        x_data[i]['embedding_cluster'] = kmeans.labels_[i]\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classifier models\n",
    "# redefine for quicker running\n",
    "clf_map = [\n",
    "    (\n",
    "        LinearSVC(),\n",
    "        {\n",
    "            'clf__C': [.1],\n",
    "            'clf__penalty': ['l2'],\n",
    "            'clf__loss': ['hinge', 'squared_hinge'],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        LogisticRegression(),\n",
    "        {\n",
    "            'clf__penalty': ['l2'],\n",
    "            'clf__fit_intercept': [True],\n",
    "            'clf__C':[.1],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        RandomForestClassifier(random_state=2557),\n",
    "        {\n",
    "            'clf__n_estimators': [20],\n",
    "            'clf__max_features': [\"auto\", \"log2\"]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing spherical kmeans\n",
      "{'embedding_cluster': 38, 'total_number_of_words_in_turn': '1', 'Stanford_PoS': 'NN', 'word_number_of_syllables': 1, 'word': 'yup', 'total_number_of_words_in_task': '50', 'word_number_in_turn': '1', 'word_number_in_task': '1'}\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'word',\n",
    "    'word_number_of_syllables',\n",
    "    'word_number_in_turn',\n",
    "    'word_number_in_task',\n",
    "    'total_number_of_words_in_turn',\n",
    "    'total_number_of_words_in_task',\n",
    "    'Stanford_PoS',\n",
    "]\n",
    "\n",
    "continuous_feats = [\n",
    "    'word_number_of_syllables',\n",
    "#     'word_number_in_turn',\n",
    "#     'word_number_in_task',\n",
    "#     'total_number_of_words_in_turn',\n",
    "#     'total_number_of_words_in_task',\n",
    "]\n",
    "\n",
    "x_data, y_data = generate_data(FILE_NAME, features, continuous_feats)\n",
    "# add_dist_end_turn(x_data)\n",
    "# add_pos_bigram(x_data)\n",
    "# add_is_stutter(x_data)\n",
    "\n",
    "# get_input_mentioned(x_data)\n",
    "# set_input_num_mentions(x_data)\n",
    "# get_input_far_back_mentioned(x_data)\n",
    "# add_embeddings(x_data, gembeddings_index)\n",
    "kmeans = add_embedding_cluster(x_data, gembeddings_index, sphere=True, clusters=50)\n",
    "\n",
    "# excluded_features = ['Most_Recent_Mention','word_end_time']\n",
    "# for entry in x_data:\n",
    "#     for feature in excluded_features:\n",
    "#         if feature in entry:\n",
    "#             entry.pop(feature)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2557)\n",
    "print(x_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cluster50.sphere.twitter200d.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans.labels_, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWITTER 50 EMBED-FEATURES\n",
      "################################### LinearSVC ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  5.9min remaining:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 603.860s\n",
      "Best score: 0.666\n",
      "\tclf__C: 0.1\n",
      "\tclf__loss: 'squared_hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.96      0.92     11618\n",
      "       True       0.69      0.39      0.49      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.85     14066\n",
      "\n",
      "0.8629318925067538\n",
      "################################### LogisticRegression ###################################\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.2min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 324.970s\n",
      "Best score: 0.668\n",
      "\tclf__C: 0.1\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.97      0.92     11618\n",
      "       True       0.72      0.37      0.49      2448\n",
      "\n",
      "avg / total       0.85      0.86      0.85     14066\n",
      "\n",
      "0.8649225081757429\n",
      "################################### RandomForestClassifier ###################################\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  6.8min remaining:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 743.293s\n",
      "Best score: 0.618\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.96      0.92     11618\n",
      "       True       0.66      0.36      0.47      2448\n",
      "\n",
      "avg / total       0.84      0.86      0.84     14066\n",
      "\n",
      "0.8570311389165364\n"
     ]
    }
   ],
   "source": [
    "print(\"TWITTER 50 EMBED-FEATURES\")\n",
    "for (clf, param_grid) in clf_map:\n",
    "    pipeline = Pipeline([\n",
    "        ('dictvec', dict_vectorizer),\n",
    "    #         ('selector', select_percentile),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    best_score, best_model = classify_my_model(pipeline, param_grid, X_train, y_train, clf.__class__.__name__, scorer=fdot25_scorer)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        \n",
    "def show_least_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names), key=lambda x: abs(x[0]))\n",
    "    top = coefs_with_fns[:n]\n",
    "    for (coef_1, fn_1) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\" % (coef_1, fn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_most_informative_features(model.steps[0][1], model.steps[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_least_informative_features(model.steps[0][1], model.steps[2][1], n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.steps[2][1].coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def show_feature_importance(vectorizer, clf):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = zip(clf.coef_[0], feature_names)\n",
    "    feat_count = defaultdict(list)\n",
    "    for (coef_1, fn_1) in coefs_with_fns:\n",
    "        feat = fn_1.split('=')[0]\n",
    "        feat_count[feat].append(abs(coef_1))\n",
    "    for feat in feat_count.keys():\n",
    "        print(feat, sum(feat_count[feat])/len(feat_count[feat]))\n",
    "    return feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_count = show_feature_importance(model.steps[0][1], model.steps[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feat in feat_count.keys():\n",
    "    hist, bins = np.histogram(feat_count[feat], bins=int(len(feat_count[feat])**0.5))\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.title(feat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
