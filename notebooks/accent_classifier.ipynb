{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../info-status/games-data-20180420.csv\")\n",
    "\n",
    "# Part of Speech tags that are considered to be referring expressions\n",
    "REFERRING_EXP_POS = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"CD\", \"POS\", \"PRP\", \"PRP$\"]\n",
    "\n",
    "# List of features to extract from the table\n",
    "FEATURE_LIST = ['tree_depth', 'tree_width', 'word_depth', 'constituent_width', 'constituent_label',\n",
    "                'constituent_forward_position', 'constituent_backward_position',\n",
    "                'word_end_time', 'Intonational_Phrase_ID', 'Number_Of_Coref_Mentions',\n",
    "                'Most_Recent_Mention', 'word_pos_tag',\n",
    "                'word_tobi_break_index', 'word_tobi_pitch_accent']\n",
    "\n",
    "\n",
    "def filter_referring_expressions(df):\n",
    "    '''\n",
    "    Returns a dataframe only containing row with referring expressions\n",
    "    \n",
    "    :param df dataframe to be filtered\n",
    "    '''\n",
    "    return df.loc[df['word_pos_tag'].isin(REFERRING_EXP_POS)]\n",
    "\n",
    "df = df[FEATURE_LIST]\n",
    "# Comment out the line below to run experiments on all tokens instead of just referring expressions\n",
    "df = filter_referring_expressions(df)\n",
    "\n",
    "def get_labels(df):\n",
    "    '''\n",
    "    Retrieves accented labels from each row in the table\n",
    "    Token is considered to be accented if its value for column 'word_tobi_pitch_accent' is not '*?' or '_'\n",
    "    \n",
    "    :param df dataframe to retrieve labels from \n",
    "    '''\n",
    "    accent_columns = df[['word_tobi_break_index', 'word_tobi_pitch_accent']]\n",
    "    \n",
    "    y_labels = []\n",
    "    \n",
    "    for index, row in accent_columns.iterrows():\n",
    "        \n",
    "        if row['word_tobi_pitch_accent'] == \"*?\":\n",
    "            y_labels.append(0)\n",
    "            \n",
    "        elif row['word_tobi_pitch_accent'] == \"_\":\n",
    "            y_labels.append(0)\n",
    "            \n",
    "        else:\n",
    "            y_labels.append(1)\n",
    "            \n",
    "    return pd.Series(y_labels, dtype=int).to_frame(\"Labels\")\n",
    "\n",
    "def convert_pos_to_feature(df):\n",
    "    '''\n",
    "    Converts Part of Speech feature within a dataframe into integer representation in order to be used as a \n",
    "    feature for classifiers\n",
    "    \n",
    "    :param df dataframe that contains PoS column\n",
    "    '''   \n",
    "    pos_set = set()\n",
    "    pos_dict = dict()\n",
    "    converted_pos = np.array([])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        pos_set.add(row['word_pos_tag'])\n",
    "        \n",
    "    for idx, item in enumerate(pos_set):\n",
    "        pos_dict[item] = idx\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        converted_pos = np.append(converted_pos, pos_dict[row['word_pos_tag']])\n",
    "        \n",
    "    return pd.Series(converted_pos).to_frame('word_pos_tag')\n",
    "\n",
    "def get_input_has_been_mentioned(df):\n",
    "    '''\n",
    "    Generates binary value feature column that determines whether a token as been mentioned before or not.\n",
    "    '''\n",
    "    return (df['Most_Recent_Mention'] > 0).astype(int).to_frame(\"Has_Been_Mentioned\")\n",
    "\n",
    "def get_input_num_mentions(df):\n",
    "    '''\n",
    "    Generates a feature with a count for how many Coreferences a token has\n",
    "    '''\n",
    "    return np.maximum(df['Number_Of_Coref_Mentions'], 0).fillna(value=0).astype(int).to_frame('Num_Mentions')\n",
    "\n",
    "def get_input_far_back_mentioned(df):\n",
    "    '''\n",
    "    Generates a feature that determines how far back temporally a token was mentioned\n",
    "    If it wasn't previously mentioned the feature value is set to the max value for float32\n",
    "    '''\n",
    "    return (df['word_end_time'] - df['Most_Recent_Mention']).to_frame('Far_Back_Mentioned').fillna(value=np.finfo('float32').min)\n",
    "\n",
    "def num_tokens_intonational_phrase_prev_mention(df, use_percentage=False):\n",
    "    '''\n",
    "    Get percentage of all referring expressions in an intonational phrase that have been mentioned before\n",
    "    or determine whehther all referring expressions in an IP have been mentioned before.\n",
    "    \n",
    "    Generates feature with length of the Intonational Phrase the token is a part of\n",
    "    \n",
    "    Generates features with the normalized position of the token within its intonational phrase\n",
    "    \n",
    "    :param df Dataframe to filter from\n",
    "    :param bool use_percentage Flag that determines whether to calculate percentage or not.    \n",
    "    '''\n",
    "    \n",
    "    df = pd.concat([df['Intonational_Phrase_ID'], get_input_has_been_mentioned(df)], axis=1)\n",
    "\n",
    "    ip_id = -1\n",
    "    counter = 0\n",
    "    curr_ip_id = 1\n",
    "    ip_series = np.array([])\n",
    "    ip_length = np.array([])\n",
    "    ip_pos_norm = np.array([])\n",
    "\n",
    "    ip_groups = df.groupby(['Intonational_Phrase_ID'])\n",
    "    \n",
    "    group_keys = ip_groups.groups.keys()\n",
    "    \n",
    "    for i in group_keys:\n",
    "        counter = 0\n",
    "        value = 1\n",
    "        for idx, row in enumerate(ip_groups.get_group(i)['Has_Been_Mentioned']):\n",
    "\n",
    "            # Count how many referring expressions have been previously mentioned             \n",
    "            if row == 1:\n",
    "                counter += 1\n",
    "\n",
    "            # Detect if a referring expression in IP has not been previously mentioned\n",
    "            if row != 1:\n",
    "                value = 0\n",
    "\n",
    "            if idx > 0:\n",
    "                ip_pos_norm = np.append(ip_pos_norm, idx / len(ip_groups.get_group(i)))                    \n",
    "            else:\n",
    "                ip_pos_norm = np.append(ip_pos_norm, 0)\n",
    "\n",
    "        if use_percentage:\n",
    "            ip_series = np.append(ip_series, np.full(len(ip_groups.get_group(i)), counter / len(ip_groups.get_group(i))))\n",
    "        else:\n",
    "            ip_series = np.append(ip_series, np.full(len(ip_groups.get_group(i)), value))\n",
    "\n",
    "        ip_length = np.append(ip_length, np.full(len(ip_groups.get_group(i)), len(ip_groups.get_group(i))))\n",
    "\n",
    "    df_ip_mentions = pd.Series(ip_series).to_frame(\"IP_Prev_Mentions\").fillna(0)\n",
    "    df_ip_length = pd.Series(ip_length).to_frame(\"IP_Length\").fillna(0)\n",
    "    df_ip_pos_norm = pd.Series(ip_pos_norm).to_frame(\"IP_Pos_Normalized\").fillna(0)           \n",
    "            \n",
    "    return df_ip_pos_norm.join(df_ip_mentions.join(df_ip_length))\n",
    "\n",
    "def get_syntactic_features(df):\n",
    "    '''\n",
    "    Return syntactic features from the dataframe\n",
    "    \n",
    "    Converts the 'constituent_label' feature to integer representation for use in classification\n",
    "    '''\n",
    "    \n",
    "    df = df[['tree_depth', 'tree_width', 'word_depth', 'constituent_width',\n",
    "             'constituent_label', 'constituent_forward_position', 'constituent_backward_position']]\n",
    "    \n",
    "    label_set = set()\n",
    "    label_dict = dict()\n",
    "    converted_labels = np.array([])\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        label_set.add(row['constituent_label'])\n",
    "        \n",
    "    for i, label in enumerate(label_set):\n",
    "        label_dict[label] = i\n",
    "                     \n",
    "    for idx, row in df.iterrows():\n",
    "        converted_labels = np.append(converted_labels, label_dict[row['constituent_label']])\n",
    "        \n",
    "    df['constituent_label'] = pd.Series(converted_labels).values\n",
    "    \n",
    "    return df\n",
    "\n",
    "def classifyNB(x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Naive Bayes classifier\n",
    "    '''\n",
    "    \n",
    "    gsclf = BernoulliNB()\n",
    "    gsclf.fit(x_train, y_train)\n",
    "    y_pred = gsclf.predict(x_test)\n",
    "\n",
    "    print_accuracy_f1_scores(\"Naive Bayes\", gsclf, x_test, y_test, gsclf.predict(x_test))\n",
    "    \n",
    "def classifyRF(x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Random Forest classifier\n",
    "    '''\n",
    "    \n",
    "    # Create the random grid\n",
    "    param_grid = { \n",
    "        'n_estimators': [100, 900],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    clf = RFC(max_features = 'auto', n_estimators = 700)\n",
    "    \n",
    "#     clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 5)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "#     print(clf.best_params_)\n",
    "\n",
    "    print_accuracy_f1_scores(\"Random Forest\", clf, x_test, y_test, clf.predict(x_test))\n",
    "    \n",
    "def classifyLR(x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Logistic Regression classifier\n",
    "    '''\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    print_accuracy_f1_scores(\"LR\", clf, x_test, y_test, clf.predict(x_test))\n",
    "    \n",
    "def classifySVM(x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Support vector classifier\n",
    "    '''\n",
    "    \n",
    "    gsclf = LinearSVC()\n",
    "    gsclf.fit(x_train, y_train)\n",
    "    y_pred = gsclf.predict(x_test)\n",
    "\n",
    "    print_accuracy_f1_scores(\"SVM\", gsclf, x_test, y_test, gsclf.predict(x_test))\n",
    "    \n",
    "def print_accuracy_f1_scores(classifier_name, clf, x_test, y_test, y_pred):\n",
    "    '''\n",
    "    Print a classifier's accuracy, F1 score, and classification report\n",
    "    '''\n",
    "    \n",
    "    print(classifier_name + \" Accuracy : {:.2f}%\".format(clf.score(x_test, y_test) * 100))\n",
    "    print(classifier_name + \" F1-Score: {:.2f}\".format(f1_score(y_test, y_pred)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    count = np.bincount(y_pred)\n",
    "    print(\"Unaccented Count:\", count[0])\n",
    "    print(\"Accented Count:\", count[1])\n",
    "    \n",
    "    print(80 * \"=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: RuntimeWarning: invalid value encountered in maximum\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Generate and join all features into one dataframe\n",
    "\n",
    "columns = get_input_has_been_mentioned(df).join(get_input_num_mentions(df))\n",
    "columns = columns.join(get_input_far_back_mentioned(df))\n",
    "columns = columns.reset_index(drop=True)\n",
    "columns = columns.join(num_tokens_intonational_phrase_prev_mention(df, use_percentage=False))\n",
    "columns = columns.join(get_syntactic_features(df))\n",
    "columns = columns.join(get_labels(df))\n",
    "columns = columns.join(convert_pos_to_feature(df))\n",
    "columns = columns.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifiers on a single feature\n",
    "def run_classifiers_on_single_feature(features, labels):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[0], labels, random_state = 1)\n",
    "    x_train = x_train.values.reshape(-1, 1)\n",
    "    x_test = x_test.values.reshape(-1, 1)\n",
    "\n",
    "    print()\n",
    "    print(\"Features:\", [f.name for f in features])\n",
    "    classifyLR(x_train, x_test, y_train, y_test)\n",
    "    classifyNB(x_train, x_test, y_train, y_test)\n",
    "    classifyRF(x_train, x_test, y_train, y_test)\n",
    "    classifySVM(x_train, x_test, y_train, y_test)\n",
    "    print()\n",
    "\n",
    "# Run classifiers on multiple features\n",
    "def run_classifiers_on_multiple_features(ref_df, columns):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(ref_df[columns], ref_df['Labels'], random_state = 1)\n",
    "    \n",
    "    print()\n",
    "    print(\"Features:\", columns)\n",
    "    classifyLR(x_train, x_test, y_train, y_test)\n",
    "    classifyNB(x_train, x_test, y_train, y_test)\n",
    "    classifyRF(x_train, x_test, y_train, y_test)\n",
    "    classifySVM(x_train, x_test, y_train, y_test)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_single_feature([columns['Has_Been_Mentioned']], columns['Labels'])\n",
    "# run_classifiers_on_single_feature([columns['Num_Mentions']], columns['Labels'])\n",
    "# run_classifiers_on_single_feature([columns['Far_Back_Mentioned']], columns['Labels'])\n",
    "# run_classifiers_on_single_feature([columns['IP_Prev_Mentions']], columns['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'Num_Mentions'])\n",
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'Far_Back_Mentioned'])\n",
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'IP_Prev_Mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_multiple_features(columns, ['Num_Mentions', 'Far_Back_Mentioned'])\n",
    "# run_classifiers_on_multiple_features(columns, ['Num_Mentions', 'IP_Prev_Mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_multiple_features(columns, ['Far_Back_Mentioned', 'IP_Prev_Mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'Far_Back_Mentioned', 'IP_Prev_Mentions'])\n",
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'Num_Mentions', 'IP_Prev_Mentions'])\n",
    "# run_classifiers_on_multiple_features(columns, ['Num_Mentions', 'Far_Back_Mentioned', 'IP_Prev_Mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_classifiers_on_multiple_features(columns, ['Has_Been_Mentioned', 'Num_Mentions', 'Far_Back_Mentioned', 'IP_Prev_Mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['tree_depth', 'tree_width', 'word_depth', 'constituent_width', 'Has_Been_Mentioned', 'Num_Mentions', 'Far_Back_Mentioned', 'IP_Prev_Mentions', 'constituent_label', 'constituent_forward_position', 'constituent_backward_position', 'word_pos_tag']\n",
      "LR Accuracy : 61.26%\n",
      "LR F1-Score: 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.49      0.35       975\n",
      "          1       0.82      0.65      0.72      3609\n",
      "\n",
      "avg / total       0.71      0.61      0.64      4584\n",
      "\n",
      "Unaccented Count: 1759\n",
      "Accented Count: 2825\n",
      "================================================================================\n",
      "Naive Bayes Accuracy : 80.52%\n",
      "Naive Bayes F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.38      0.45       975\n",
      "          1       0.85      0.92      0.88      3609\n",
      "\n",
      "avg / total       0.79      0.81      0.79      4584\n",
      "\n",
      "Unaccented Count: 656\n",
      "Accented Count: 3928\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy : 84.01%\n",
      "Random Forest F1-Score: 0.90\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.51      0.58       975\n",
      "          1       0.88      0.93      0.90      3609\n",
      "\n",
      "avg / total       0.83      0.84      0.83      4584\n",
      "\n",
      "Unaccented Count: 752\n",
      "Accented Count: 3832\n",
      "================================================================================\n",
      "SVM Accuracy : 80.87%\n",
      "SVM F1-Score: 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.11      0.20       975\n",
      "          1       0.81      1.00      0.89      3609\n",
      "\n",
      "avg / total       0.82      0.81      0.74      4584\n",
      "\n",
      "Unaccented Count: 126\n",
      "Accented Count: 4458\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete features list for use with classifiers\n",
    "f_list = ['tree_depth', 'tree_width', 'word_depth', 'constituent_width',\n",
    "         'Has_Been_Mentioned', 'Num_Mentions', 'Far_Back_Mentioned', 'IP_Prev_Mentions',\n",
    "          'constituent_label', 'constituent_forward_position', 'constituent_backward_position', 'word_pos_tag']\n",
    "\n",
    "run_classifiers_on_multiple_features(columns, f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class baseline classifier accuracy: 78.03%\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.bincount(columns['Labels'])\n",
    "print(\"Majority class baseline classifier accuracy: {:.2f}%\".format((max(label_counts) / np.sum(label_counts)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10360  7973]\n",
      "Percentage of tokens with previous mention: 43.49%\n"
     ]
    }
   ],
   "source": [
    "mention_counts = np.bincount(columns['Has_Been_Mentioned'])\n",
    "print(mention_counts)\n",
    "print(\"Percentage of tokens with previous mention: {:.2f}%\".format((mention_counts[1] / np.sum(mention_counts)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1811 2217]\n",
      "Percentage of 0 label with previous mention: 55.04%\n",
      "[8549 5756]\n",
      "Percentage of 1 label with previous mention: 40.24%\n"
     ]
    }
   ],
   "source": [
    "accent_groups = columns.groupby(['Labels'])\n",
    "\n",
    "for i in accent_groups.groups.keys():\n",
    "    accent_counts = np.bincount(accent_groups.get_group(i)['Has_Been_Mentioned'])\n",
    "    print(accent_counts)\n",
    "    print(\"Percentage of {} label with previous mention: {:.2f}%\".format(i, (accent_counts[1] / np.sum(accent_counts)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2217 5756]\n",
      "Percentage of previously mentioned tokens that are unaccented: 27.81%\n",
      "Percentage of previously mentioned tokens that are accented: 72.19%\n"
     ]
    }
   ],
   "source": [
    "accent_groups = columns.groupby(['Has_Been_Mentioned'])\n",
    "\n",
    "accent_counts = np.bincount(accent_groups.get_group(1)['Labels'])\n",
    "print(accent_counts)\n",
    "print(\"Percentage of previously mentioned tokens that are unaccented: {:.2f}%\".format((accent_counts[0] / np.sum(accent_counts)) * 100))\n",
    "print(\"Percentage of previously mentioned tokens that are accented: {:.2f}%\".format((accent_counts[1] / np.sum(accent_counts)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
