{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../info-status/games-data-20180420.csv\")\n",
    "REFERRING_EXP_POS = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"CD\", \"POS\", \"PRP\", \"PRP$\"]\n",
    "\n",
    "def filter_referring_expressions(df):    \n",
    "    return df.loc[df['word_pos_tag'].isin(REFERRING_EXP_POS)]\n",
    "\n",
    "df = filter_referring_expressions(df)\n",
    "\n",
    "def get_labels(df):\n",
    "    accent_columns = df[['word_tobi_break_index', 'word_tobi_pitch_accent']]\n",
    "    \n",
    "    y_labels = []\n",
    "    \n",
    "    for index, row in accent_columns.iterrows():\n",
    "        \n",
    "        if row['word_tobi_pitch_accent'] == \"*?\":\n",
    "            y_labels.append(0)\n",
    "            \n",
    "        elif row['word_tobi_pitch_accent'] == \"_\":\n",
    "            y_labels.append(0)\n",
    "            \n",
    "        else:\n",
    "            y_labels.append(1)\n",
    "            \n",
    "    return pd.Series(y_labels, dtype=int).to_frame(\"Labels\")\n",
    "\n",
    "def get_input_has_been_mentioned(df):\n",
    "    return (df['Most_Recent_Mention'] > 0).astype(int).to_frame(\"Has_Been_Mentioned\")\n",
    "\n",
    "def get_input_num_mentions(df):\n",
    "    return np.maximum(df['Number_Of_Coref_Mentions'], 0).fillna(value=0).astype(int).to_frame('Num_Mentions')\n",
    "\n",
    "def get_input_far_back_mentioned(df):\n",
    "    return (df['word_end_time'] - df['Most_Recent_Mention']).to_frame('Far_Back_Mentioned').fillna(value=np.finfo('float32').min)\n",
    "\n",
    "def num_tokens_intonational_phrase_prev_mention(df, use_percentage=False):\n",
    "    '''\n",
    "    Get percentage of all referring expressions in an intonational phrase that have been mentioned before\n",
    "    or determine whehther all referring expressions in an IP have been mentioned before.\n",
    "    \n",
    "    :param df Dataframe to filter from\n",
    "    :param bool use_percentage Flag that determines whether to calculate percentage or not.    \n",
    "    '''\n",
    "    \n",
    "    df = pd.concat([df['Intonational_Phrase_ID'], get_input_has_been_mentioned(df)], axis=1)\n",
    "\n",
    "    ip_id = -1\n",
    "    counter = 0\n",
    "    curr_ip_id = 1\n",
    "    ip_series = np.array([])\n",
    "\n",
    "    ip_groups = df.groupby(['Intonational_Phrase_ID'])\n",
    "    \n",
    "    group_keys = ip_groups.groups.keys()\n",
    "    \n",
    "    if use_percentage:\n",
    "        for i in group_keys:\n",
    "            counter = 0\n",
    "            for row in ip_groups.get_group(i)['Has_Been_Mentioned']:\n",
    "                if row == 1:\n",
    "                    counter += 1\n",
    "\n",
    "            ip_series = np.append(ip_series, np.full(len(ip_groups.get_group(i)), counter / len(ip_groups.get_group(i))))\n",
    "    \n",
    "    else:\n",
    "        for i in group_keys:\n",
    "            value = 1\n",
    "            for row in ip_groups.get_group(i)['Has_Been_Mentioned']:\n",
    "                if row != 1:\n",
    "                    value = 0\n",
    "\n",
    "            ip_series = np.append(ip_series, np.full(len(ip_groups.get_group(i)), value))\n",
    "\n",
    "\n",
    "    return pd.Series(ip_series).to_frame(\"IP_Prev_Mentions\").fillna(0)\n",
    "\n",
    "def classifyNB(x_train, x_test, y_train, y_test):\n",
    "    gsclf = BernoulliNB()\n",
    "    gsclf.fit(x_train, y_train)\n",
    "    y_pred = gsclf.predict(x_test)\n",
    "\n",
    "    print_accuracy_f1_scores(\"Naive Bayes\", gsclf, x_test, y_test, gsclf.predict(x_test))\n",
    "    \n",
    "def classifyRF(x_train, x_test, y_train, y_test):\n",
    "    clf = RFC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print_accuracy_f1_scores(\"Random Forest\", clf, x_test, y_test, clf.predict(x_test))\n",
    "    \n",
    "def classifyLR(x_train, x_test, y_train, y_test):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    print_accuracy_f1_scores(\"LR\", clf, x_test, y_test, clf.predict(x_test))\n",
    "    \n",
    "def classifySVM(x_train, x_test, y_train, y_test):\n",
    "    gsclf = LinearSVC()\n",
    "    gsclf.fit(x_train, y_train)\n",
    "    y_pred = gsclf.predict(x_test)\n",
    "\n",
    "    print_accuracy_f1_scores(\"SVM\", gsclf, x_test, y_test, gsclf.predict(x_test))\n",
    "    \n",
    "def print_accuracy_f1_scores(classifier_name, clf, x_test, y_test, y_pred):\n",
    "    print(classifier_name + \" Accuracy : {:.2f}%\".format(clf.score(x_test, y_test) * 100))\n",
    "    print(classifier_name + \" F1-Score: {:.2f}\".format(f1_score(y_test, y_pred)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    count = np.bincount(y_pred)\n",
    "    print(\"Unaccented Count:\", count[0])\n",
    "    print(\"Accented Count:\", count[1])\n",
    "    \n",
    "    print(80 * \"=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in maximum\n"
     ]
    }
   ],
   "source": [
    "columns = get_input_has_been_mentioned(df).join(get_input_num_mentions(df))\n",
    "columns = columns.join(get_input_far_back_mentioned(df))\n",
    "columns = columns.reset_index(drop=True)\n",
    "columns = columns.join(num_tokens_intonational_phrase_prev_mention(df))\n",
    "columns = columns.join(get_labels(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers_on_columns(features, labels):\n",
    "    \n",
    "    if len(features) == 1:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(features[0], labels, random_state = 1)\n",
    "        x_train = x_train.values.reshape(-1, 1)\n",
    "        x_test = x_test.values.reshape(-1, 1)\n",
    "        \n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(filtered_df[columns], filtered_df[1], random_state = 1)\n",
    "        x_train = x_train.values.reshape(-1, len(columns[0]))\n",
    "        x_test = x_test.values.reshape(-1, len(columns[0]))\n",
    "        \n",
    "    \n",
    "    print()\n",
    "    print(\"Features:\", [f.name for f in features])\n",
    "    classifyLR(x_train, x_test, y_train, y_test)\n",
    "    classifyNB(x_train, x_test, y_train, y_test)\n",
    "    classifyRF(x_train, x_test, y_train, y_test)\n",
    "    classifySVM(x_train, x_test, y_train, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['Has_Been_Mentioned']\n",
      "LR Accuracy : 78.73%\n",
      "LR F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Naive Bayes Accuracy : 78.73%\n",
      "Naive Bayes F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Random Forest Accuracy : 78.73%\n",
      "Random Forest F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "SVM Accuracy : 78.73%\n",
      "SVM F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Features: ['Num_Mentions']\n",
      "LR Accuracy : 78.73%\n",
      "LR F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Naive Bayes Accuracy : 78.73%\n",
      "Naive Bayes F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Random Forest Accuracy : 81.33%\n",
      "Random Forest F1-Score: 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.14      0.24       975\n",
      "          1       0.81      1.00      0.89      3609\n",
      "\n",
      "avg / total       0.83      0.81      0.75      4584\n",
      "\n",
      "Unaccented Count: 145\n",
      "Accented Count: 4439\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy : 77.84%\n",
      "SVM F1-Score: 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.01      0.02       975\n",
      "          1       0.79      0.99      0.87      3609\n",
      "\n",
      "avg / total       0.66      0.78      0.69      4584\n",
      "\n",
      "Unaccented Count: 67\n",
      "Accented Count: 4517\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Features: ['Far_Back_Mentioned']\n",
      "LR Accuracy : 61.26%\n",
      "LR F1-Score: 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.49      0.35       975\n",
      "          1       0.82      0.65      0.72      3609\n",
      "\n",
      "avg / total       0.71      0.61      0.64      4584\n",
      "\n",
      "Unaccented Count: 1759\n",
      "Accented Count: 2825\n",
      "================================================================================\n",
      "Naive Bayes Accuracy : 78.73%\n",
      "Naive Bayes F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Random Forest Accuracy : 73.89%\n",
      "Random Forest F1-Score: 0.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.16      0.21       975\n",
      "          1       0.80      0.89      0.84      3609\n",
      "\n",
      "avg / total       0.69      0.74      0.71      4584\n",
      "\n",
      "Unaccented Count: 542\n",
      "Accented Count: 4042\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy : 40.64%\n",
      "SVM F1-Score: 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.47      0.25       975\n",
      "          1       0.73      0.39      0.51      3609\n",
      "\n",
      "avg / total       0.61      0.41      0.45      4584\n",
      "\n",
      "Unaccented Count: 2658\n",
      "Accented Count: 1926\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Features: ['IP_Prev_Mentions']\n",
      "LR Accuracy : 78.73%\n",
      "LR F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Naive Bayes Accuracy : 78.73%\n",
      "Naive Bayes F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "Random Forest Accuracy : 78.73%\n",
      "Random Forest F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "SVM Accuracy : 78.73%\n",
      "SVM F1-Score: 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       975\n",
      "          1       0.79      1.00      0.88      3609\n",
      "\n",
      "avg / total       0.62      0.79      0.69      4584\n",
      "\n",
      "Unaccented Count: 0\n",
      "Accented Count: 4584\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_classifiers_on_columns([columns['Has_Been_Mentioned']], columns['Labels'])\n",
    "run_classifiers_on_columns([columns['Num_Mentions']], columns['Labels'])\n",
    "run_classifiers_on_columns([columns['Far_Back_Mentioned']], columns['Labels'])\n",
    "run_classifiers_on_columns([columns['IP_Prev_Mentions']], columns['Labels'])\n",
    "# run_classifiers_on_columns([['Most_Recent_Mention', 'Number_Of_Coref_Mentions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class baseline classifier accuracy: 78.03%\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.bincount(columns['Labels'])\n",
    "print(\"Majority class baseline classifier accuracy: {:.2f}%\".format((max(label_counts) / np.sum(label_counts)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
